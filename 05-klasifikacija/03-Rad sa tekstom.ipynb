{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rad sa tekstom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U zajednici koja se bavi obradom prirodnih jezika (engl. Natural Language Processing) postoji nekoliko popularnih biblioteka među kojima svakako prednjače [NLTK](https://www.nltk.org/), [SpaCy](https://spacy.io/) i [FastText](https://fasttext.cc/). U primerima koji sledi biće opisana biblioteka NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteka NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK je biblioteka koja ima najdužu istoriju i koji nudi najviše mogućnosti u radu sa tekstom. Koriste je lingvisti, istraživači koji se bave digitalnom humanistikom, kao i istraživači u domenu obrade prirodnih jezika. Više o samoj biblioteci i njenim funkcionalnostima se može pročitati na [zvaničnom sajtu](https://www.nltk.org/), a nadalje slede primeri nekoliko najvažnijih i najčešće korišćenih metoda. Biblioteka podržava rad sa velikim brojem jezika, a primeri koji slede će se odnositi na engleski jezik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK biblioteka tj. istoimeni paket se može instalirati pomoću alata `conda` komandom `conda install -c anaconda nltk` u skladu sa [zvaničnim smernicama](https://anaconda.org/anaconda/nltk). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/andjelka/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/andjelka/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekst koji ćemo koristiti za vežbu preuzet je sa Vikipedijinog članka o Nikoli Tesli na engleskom jeziku.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"Born and raised in the Austrian Empire, Mr. Tesla studied engineering and physics in the 1870s without receiving a degree, and gained practical experience in the early 1880s working in telephony and at Continental Edison in the new electric power industry. He emigrated in 1884 to the U.S.A., where he became a naturalized citizen. He worked for a short time at the Edison Machine Works in New York City before he struck out on his own.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Born and raised in the Austrian Empire, Mr. Tesla studied engineering and physics in the 1870s without receiving a degree, and gained practical experience in the early 1880s working in telephony and at Continental Edison in the new electric power industry. He emigrated in 1884 to the U.S.A., where he became a naturalized citizen. He worked for a short time at the Edison Machine Works in New York City before he struck out on his own.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inteligentna podela teksta na rečenice se postiže pozivom metode `sent_tokenizer`. Kao separatori se koriste znaci interpunkcije poput tačke, upitnika ili uzvičnika. Metoda je sposobna da prepozna pojave ovih karatkera i u drugim kontekstima i pridruži im ispravnu funkciju. Na primer, tačka koja je sastavni deo skraćenica U.S.A. ili datuma 20.02.2020. neće uticati na pogrešno razbijanje rečenice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rečenice se dalje mogu deliti na tokene. To se postiže pozivom metode `word_tokenize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'He worked,  for a short time, at the Edison Machine Works in New York City before he struck out on his own.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovako izdvojeni tokeni se dalje mogu filtrirati. Na primer, mogu se eliminisati znaci interpunkcije ili reči koje se jako često pojavljuju i koje svojim značenjem ne doprinose zadatku. Takve reči se zovu funkcijske ili stop reči i za svaki jezik postoji lista reči koja se ubraja u ovu kategoriju. Na primer, za engleski jezik to su članovi a i the, predlozi poput in, at, on i slično. Sam izbor kriterijuma filtriranja pre svega zavisi od zadatka i ne može se grubo generalizovati. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svi interpunkcijski karakteri se mogu očitati iz paketa `string` koji nudi podršku u radu sa stringovima. Za očitavanje interpunkcijskih karaktera koristi se svojstvo `punctuation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop reči se mogu očitati iz paketa `stopwords` biblioteke `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lematizacija i stemovanje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakon filtriranja, tokeni se dalje mogu dalje obrađivati. Na primer, tokeni poput *plays*, *played* i *playing* bi mogli da se dovedu u vezu sa infinitivom glagola *play*, a tokeni poput *apples* ili *oranges* sa imenicama jednine *apple* i *orange*. U zavisnosti da li se ovo uvezivanje vrši po lingvističkim pravilima ili primenom heuristika, možemo govoriti o `lematizaciji` ili `stemovanju`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Porterov stemer** je jedan od najpoznatijih stemera za engleski jezik. Njime se dosledno primenjuje niz pravila kako bi se dobio `stem` - veštački koren reči. Na primer, neka pravila su odsecanje *ed* sufiksa (played->play), zamena sufiksa *ational* sufiksom *ate* (relational->relate) ili *ization* sufiksom *ize* (organization->organize). Osim ovakvih pravila postoje i pravila koja se zasnivaju na analizi vokala i konsonanata. O njima i samom algorimu se može pročitati više u [zvaničnoj dokumentaciji](https://www.nltk.org/_modules/nltk/stem/porter.html). Neke popularne alternative Porterovom stemeru su SnowballStemmer, LancasterStemmer, RegexpStemmer i drugi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za razliku od stemovanja, lematizacijom se tokenu pridružuje gramatički koren (takozvana lema). Na primer, glagolu *are* se pridružuje lema *be*, a imenici *boxes* lema *box*. NLTK paket nudi mogućnost rada sa [WordNet](https://wordnet.princeton.edu/) lematizatorom, manualno kreiranom leksičkom bazom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uz token, lematizer očekuje i informaciju o vrsti reči (engl. part-of-speach) kao aproksimaciju konteksta u kojem se token nalazi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za automatsko dobijanje vrste reči, mogu se koristiti takozvani POS tager. POS tageri pridružuju tokenima odgovarajuće POS obeležje. To su obično klasifikatori za labeliranje sekvenci trenirani na velikoj kolekciji obeleženog teksta tako da maksimizuju verovatnoće pojavljivanja određenih sekvenci. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tager podrazumevano koristi takozvani PennTreebank skup tagova. U njemu, na primer, tag NNP označava vlastitu imenicu, NN imenicu, DT član, IN predlog... Detaljan opis ove sheme tagova se može pronaći [ovde](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da bi mogli da spojimo POS tager sa lematizacijom, moramo uskladiti tagove koji se pridružuju tokenima. WordNet lematizator koristi svoj skromniji skup tagova  (\"a\", \"s\", \"r\", \"n\", \"v\" redom sa znacenjima ADJ, ADJ_SAT, ADV, NOUN, VERB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "\n",
    "    # uparujemo tagove\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"S\": wordnet.ADJ_SAT,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    # izdvajamo prvi karakter taga koji bi pridruzio POS tager\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "\n",
    "    # mapiramo ga u odgovarajuci WordNet tag ili postavljamo podrazumevano obelezje imenice\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada možemo izdvojiti listu lematizovanih tokena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da li ćemo iskoristiti lematizaciju ili stemovanje zavisi od prirode zadatka koji rešavamo, kao i resursa kojima raspolažemo. Lematizacija zahteva postojanje leksičke baze nalik WordNet-u i njeno korišćenje može da uspori program, dok steming daje nešto nepreciznije rezultate ali brže. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lematizacija i stemovanje se ubrajaju u zadatke `normalizacije` teksta tj. reči. U zavisnosti od tipa tekstualnog sadržaja mogu postojati potrebe i za drugim vrstama normalizacije. Na primer, jezik na društvenim mrežama je često vrlo specifičan, obiluje mnoštvom skraćenica i reči koje odstupaju od standardnog pravopisa. Tako se, recimo, skraćenica *u2* svodi na *you too*, skraćenica *tmrw* na *tomorrow*, a *cooool* na *cool*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prethodno opisani postupci nam omogućavaju da kreiramo vokabular tj. skup svih reči koji se nalazi u nekom tekstu ili kolekciji tekstova (korpusu). Nad vokabularom dalje kreiramo atribute potrebne za primenu algoritama mašinskog učenja. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
